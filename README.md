# Unified XAI Interface for Deepfake & Lung Cancer Detection

## Authors

- **Adrien Servas**
- **Alexandre Francony**
- **LÃ©onard Seidlitz**
- **Raphael Roux**
- **Romain Requena**

## Use of AI
We used AI in this project to :
- Help us with the code implementation of XAI models
- Help us with the project structure
- Help us with debugging

The AI that we used are Chat GPT and Gemini

This project integrates two Explainable AI (XAI) systems into a single Streamlit interface:
1.  **Deepfake Audio Detection**: MobileNetV2 + LIME + SHAP
2.  **Lung Cancer Detection**: MobileNetV2 + Grad-CAM + SHAP

## âœ¨ Features

### Core Functionality
- **Dual-Mode Analysis**: Audio deepfake detection and medical image diagnosis
- **Multiple XAI Methods**: LIME, SHAP, and Grad-CAM with automatic filtering
- **Side-by-Side Comparison**: Compare different XAI methods on the same input
- **Real-Time Inference**: PyTorch-based models with GPU acceleration support

### XAI Techniques
- **LIME (Local Interpretable Model-agnostic Explanations)**: Highlights important regions
- **SHAP (SHapley Additive exPlanations)**: Feature importance visualization
- **Grad-CAM (Gradient-weighted Class Activation Mapping)**: Spatial attention heatmaps

## ğŸ“ Repository Structure
```
XAI_Project/
â”œâ”€â”€ app.py                      # Main Streamlit Application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ download_data.py            # Dataset download script
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ audio_detector/         # Audio preprocessing & training
â”‚   â”‚   â”œâ”€â”€ train.py           # Enhanced training (5 epochs, validation)
â”‚   â”‚   â”œâ”€â”€ preprocess.py      # Spectrogram generation
â”‚   â”‚   â””â”€â”€ lime_explainer.py  # LIME for audio
â”‚   â”œâ”€â”€ image_detector/         # Image preprocessing & training
â”‚   â”‚   â”œâ”€â”€ train.py           # Enhanced training (10 epochs, validation)
â”‚   â”‚   â””â”€â”€ grad_cam.py        # Grad-CAM implementation
â”‚   â””â”€â”€ common/
â”‚       â””â”€â”€ shap_explainer.py  # SHAP for both modalities
â”œâ”€â”€ models/                     # Trained model weights (.pth)
â””â”€â”€ data/                       # Datasets (linked to Kaggle cache)
```

## ğŸš€ Setup Instructions

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

**Note**: This project requires **Python 3.14+** and uses **PyTorch** (not TensorFlow).

### 2. Download Datasets (Optional)
```bash
python download_data.py
```
*Downloads ~4GB+ of data from Kaggle. Required only for training.*

### 3. Train Models (Optional)
```bash
# Train Audio Model (5 epochs, ~30-60 min)
python modules/audio_detector/train.py

# Train Image Model (10 epochs, ~1-2 hours)
python modules/image_detector/train.py
```

### 4. Run the Application
```bash
streamlit run app.py
```

## ğŸ¯ Usage

1. **Select a Tab**: Choose "Deepfake Audio" or "Lung Cancer"
2. **Upload File**: Upload a `.wav` audio file or `.jpg/.png` X-ray image
3. **Select XAI Methods**: Choose which explanation techniques to apply
4. **Analyze**: Click the analyze button to get predictions and explanations
5. **Compare**: Use the "Comparison" tab to view XAI methods side-by-side

## ğŸ”§ Technical Details

### Models
- **Architecture**: MobileNetV2 (transfer learning from ImageNet)
- **Audio Classes**: Real (0) vs Fake (1)
- **Image Classes**: Normal (0) vs Malignant (1)

### Training
- **Audio**: 5 epochs, 80/20 train/val split, Adam optimizer
- **Image**: 10 epochs, 80/20 train/val split, Adam optimizer
- **Validation**: Best model saved based on validation accuracy

### Data Processing
- **Audio**: Converted to Mel-spectrograms (224Ã—224Ã—3)
- **Image**: Resized to 224Ã—224, ImageNet normalization

## ğŸ“Š Datasets
- **Audio**: [Fake or Real Dataset](https://www.kaggle.com/datasets/mohammedabdeldayem/the-fake-or-real-dataset)
- **Image**: [CheXpert Dataset](https://www.kaggle.com/datasets/ashery/chexpert)

## ğŸ¨ Design Decisions
- **PyTorch Backend**: Chosen for Python 3.14+ compatibility (TensorFlow not supported)
- **No OpenCV**: Replaced with PIL/Matplotlib for broader compatibility
- **Automatic XAI Filtering**: Methods are pre-filtered based on input modality
- **Session State**: Results cached for comparison functionality

## ğŸ“ Project Status
âœ… All critical and important features implemented
âœ… Full PyTorch migration complete
âœ… Enhanced training with validation
âœ… SHAP integration for both modalities
âœ… Functional comparison tab
âœ… XAI method filtering

## ğŸ¤ Contributing
This is an academic project for XAI coursework.

## ğŸ“„ License
Educational use only.

